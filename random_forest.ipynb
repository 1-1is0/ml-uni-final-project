{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from tqdm  import tqdm\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the audio file\n",
    "# AUDIO_FILE = '/home/amir/uni/ml/mbusic/piano/Annelie_-_Lost.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(\"./data/*/*.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_seperate(file_list):\n",
    "    data = dict()\n",
    "    for x in file_list:\n",
    "        if os.path.getsize(x) > 100000:  # 10 K!\n",
    "            key = x.split('/')[2]\n",
    "            data.setdefault(key, list()).append(x)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('santour', 241), ('violin', 258), ('tar', 232), ('setar', 263), ('piano', 240), ('ney', 256)]\n"
     ]
    }
   ],
   "source": [
    "data = file_seperate(file_list)\n",
    "print([(k, len(v)) for k,v in data.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioFeature:\n",
    "    def __init__(self, src_path, fold, label):\n",
    "        self.src_path = src_path\n",
    "        self.fold = fold\n",
    "        self.label = label\n",
    "        self.y, self.sr = librosa.load(self.src_path, mono=True)\n",
    "        self.features = None\n",
    "\n",
    "    def _concat_features(self, feature):\n",
    "        \"\"\"\n",
    "        Whenever a self._extract_xxx() method is called in this class,\n",
    "        this function concatenates to the self.features feature vector\n",
    "        \"\"\"\n",
    "        self.features = np.hstack(\n",
    "            [self.features, feature] if self.features is not None else feature\n",
    "        )\n",
    "\n",
    "    def _extract_mfcc(self, n_mfcc=25):\n",
    "        mfcc = librosa.feature.mfcc(self.y, sr=self.sr, n_mfcc=n_mfcc)\n",
    "\n",
    "        mfcc_mean = mfcc.mean(axis=1).T\n",
    "        mfcc_std = mfcc.std(axis=1).T\n",
    "        mfcc_feature = np.hstack([mfcc_mean, mfcc_std])\n",
    "        self._concat_features(mfcc_feature)\n",
    "\n",
    "    def _extract_spectral_contrast(self, n_bands=3):\n",
    "        spec_con = librosa.feature.spectral_contrast(\n",
    "            y=self.y, sr=self.sr, n_bands=n_bands\n",
    "        )\n",
    "\n",
    "        spec_con_mean = spec_con.mean(axis=1).T\n",
    "        spec_con_std = spec_con.std(axis=1).T\n",
    "        spec_con_feature = np.hstack([spec_con_mean, spec_con_std])\n",
    "        self._concat_features(spec_con_feature)\n",
    "\n",
    "    def _extract_chroma_stft(self):\n",
    "        stft = np.abs(librosa.stft(self.y))\n",
    "        chroma_stft = librosa.feature.chroma_stft(S=stft, sr=self.sr)\n",
    "        chroma_mean = chroma_stft.mean(axis=1).T\n",
    "        chroma_std = chroma_stft.std(axis=1).T\n",
    "        chroma_feature = np.hstack([chroma_mean, chroma_std])\n",
    "        self._concat_features(chroma_feature)\n",
    "\n",
    "    def extract_features(self, *feature_list, save_local=True):\n",
    "        \"\"\"\n",
    "        Specify a list of features to extract, and a feature vector will be\n",
    "        built for you for a given Audio sample.\n",
    "        By default the extracted feature and class attributes will be saved in\n",
    "        a local directory. This can be turned off with save_local=False.\n",
    "        \"\"\"\n",
    "        extract_fn = dict(\n",
    "            mfcc=self._extract_mfcc,\n",
    "            spectral=self._extract_spectral_contrast,\n",
    "            chroma=self._extract_chroma_stft,\n",
    "        )\n",
    "\n",
    "        for feature in feature_list:\n",
    "            extract_fn[feature]()\n",
    "\n",
    "        if save_local:\n",
    "            self._save_local()\n",
    "\n",
    "    def _save_local(self, clean_source=True):\n",
    "        out_name = self.src_path.split(\"/\")[-1]\n",
    "        out_name = out_name.replace(\".mp3\", \"\")\n",
    "\n",
    "        filename = f\"./data/{self.label}/fold{self.fold}/{out_name}.pkl\"\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "        if clean_source:\n",
    "            self.y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "santour\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 241/241 [00:07<00:00, 32.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258/258 [00:06<00:00, 42.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 232/232 [00:06<00:00, 35.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [00:08<00:00, 30.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piano\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:05<00:00, 40.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ney\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:06<00:00, 42.21it/s]\n"
     ]
    }
   ],
   "source": [
    "audio_features = []\n",
    "feature_matrix = []\n",
    "labels = []\n",
    "folds = []\n",
    "fold=6\n",
    "for key, value in data.items():\n",
    "    print(key)\n",
    "    for audio_file in tqdm(value):\n",
    "        # print(audio_file)\n",
    "        fn = audio_file.split(\"/\")[-1]\n",
    "        fn = fn.replace(\".mp3\", \"\")\n",
    "        filename = f\"./data/{key}/fold{fold}/{fn}.pkl\"\n",
    "        if os.path.isfile(filename):\n",
    "            with open(filename, 'rb') as f:\n",
    "                audio = pickle.load(f)\n",
    "                # audio_features.append(audio.features)\n",
    "                feature_matrix.append(audio.features)\n",
    "                labels.append(audio.label)\n",
    "                folds.append(audio.fold)\n",
    "        else:\n",
    "            audio = AudioFeature(audio_file, 5, label=key)\n",
    "            audio.extract_features(\"mfcc\", \"spectral\", \"chroma\", save_local=True)\n",
    "            # audio_features.append(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(feature_matrix)\n",
    "y = np.array(labels)\n",
    "\n",
    "folds = np.array(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = [6 for i in range(folds.shape[0])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = np.array(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1490, 82)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_cfg = dict(\n",
    "    model=RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_jobs=10,\n",
    "        class_weight=\"balanced\",\n",
    "        n_estimators=500,\n",
    "        bootstrap=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3700664/1018057284.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeaveOneGroupOut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mval_fold_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sam' is not defined"
     ]
    }
   ],
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "val_fold_scores = []\n",
    "for train_index, test_index in logo.split(X, y, sam):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    ss = StandardScaler(copy=True)\n",
    "    X_train = ss.fit_transform(X_train)\n",
    "    X_test = ss.transform(X_test)\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_jobs=10,\n",
    "        class_weight=\"balanced\",\n",
    "        n_estimators=500,\n",
    "        bootstrap=True,\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    fold_acc = accuracy_score(y_test, y_pred)\n",
    "    val_fold_scores.append(fold_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "ss = StandardScaler(copy=True)\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_jobs=10,\n",
    "    class_weight=\"balanced\",\n",
    "    n_estimators=500,\n",
    "    bootstrap=True,\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "fold_acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ney', 'piano', 'santour', 'setar', 'tar', 'violin'], dtype='<U7')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 5, 3, 1, 2, 1, 3, 0, 3, 3, 2, 4, 1, 3, 1, 5, 3, 1, 0, 1, 3,\n",
       "       1, 3, 3, 5, 5, 0, 3, 2, 2, 1, 1, 4, 2, 5, 4, 2, 3, 3, 1, 4, 1, 0,\n",
       "       3, 2, 3, 3, 5, 4, 5, 2, 1, 2, 3, 1, 5, 4, 3, 1, 3, 1, 0, 0, 4, 0,\n",
       "       4, 1, 5, 3, 0, 1, 3, 4, 4, 4, 0, 1, 2, 3, 5, 4, 0, 3, 0, 0, 2, 0,\n",
       "       2, 2, 4, 3, 5, 1, 5, 4, 5, 0, 3, 5, 1, 3, 0, 5, 5, 3, 4, 1, 2, 0,\n",
       "       2, 4, 4, 5, 4, 5, 0, 2, 1, 3, 0, 4, 3, 5, 1, 4, 1, 3, 1, 3, 5, 5,\n",
       "       0, 1, 1, 5, 3, 2, 2, 1, 0, 2, 2, 3, 1, 3, 4, 2, 5, 4, 5, 1, 4, 2,\n",
       "       5, 2, 5, 4, 4, 3, 5, 5, 3, 0, 5, 1, 1, 2, 0, 2, 4, 4, 0, 4, 2, 0,\n",
       "       5, 1, 4, 5, 4, 3, 4, 5, 3, 1, 3, 5, 0, 5, 5, 5, 0, 0, 3, 0, 4, 4,\n",
       "       4, 4, 3, 4, 2, 0, 4, 2, 1, 0, 0, 5, 1, 3, 5, 1, 4, 0, 3, 4, 0, 4,\n",
       "       4, 1, 1, 5, 2, 1, 2, 1, 3, 0, 5, 1, 2, 2, 2, 1, 2, 5, 5, 4, 2, 2,\n",
       "       1, 5, 4, 5, 3, 3, 5, 1, 5, 0, 1, 0, 3, 2, 3, 0, 2, 0, 1, 3, 4, 5,\n",
       "       2, 1, 5, 5, 2, 1, 1, 4, 5, 4, 5, 0, 0, 4, 4, 5, 0, 0, 1, 4, 2, 2,\n",
       "       1, 1, 0, 0, 0, 5, 0, 0, 0, 0, 4, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['santour', 'ney', 'violin', 'setar', 'piano', 'santour', 'piano',\n",
       "       'setar', 'ney', 'setar', 'setar', 'santour', 'tar', 'piano',\n",
       "       'setar', 'piano', 'violin', 'setar', 'piano', 'ney', 'piano',\n",
       "       'setar', 'piano', 'setar', 'setar', 'violin', 'violin', 'ney',\n",
       "       'setar', 'santour', 'santour', 'piano', 'piano', 'tar', 'santour',\n",
       "       'violin', 'tar', 'santour', 'setar', 'setar', 'piano', 'tar',\n",
       "       'piano', 'ney', 'setar', 'santour', 'setar', 'setar', 'violin',\n",
       "       'tar', 'violin', 'santour', 'piano', 'santour', 'setar', 'piano',\n",
       "       'violin', 'tar', 'setar', 'piano', 'setar', 'piano', 'ney', 'ney',\n",
       "       'tar', 'ney', 'tar', 'piano', 'violin', 'setar', 'ney', 'piano',\n",
       "       'setar', 'tar', 'tar', 'tar', 'ney', 'piano', 'santour', 'setar',\n",
       "       'violin', 'tar', 'ney', 'setar', 'ney', 'ney', 'santour', 'ney',\n",
       "       'santour', 'santour', 'tar', 'setar', 'violin', 'piano', 'violin',\n",
       "       'tar', 'violin', 'ney', 'setar', 'violin', 'piano', 'setar', 'ney',\n",
       "       'violin', 'violin', 'setar', 'tar', 'piano', 'santour', 'ney',\n",
       "       'santour', 'tar', 'tar', 'violin', 'tar', 'violin', 'ney',\n",
       "       'santour', 'piano', 'setar', 'ney', 'tar', 'setar', 'violin',\n",
       "       'piano', 'tar', 'piano', 'setar', 'piano', 'setar', 'violin',\n",
       "       'violin', 'ney', 'piano', 'piano', 'violin', 'setar', 'santour',\n",
       "       'santour', 'piano', 'ney', 'santour', 'santour', 'setar', 'piano',\n",
       "       'setar', 'tar', 'santour', 'violin', 'tar', 'violin', 'piano',\n",
       "       'tar', 'santour', 'violin', 'santour', 'violin', 'tar', 'tar',\n",
       "       'setar', 'violin', 'violin', 'setar', 'ney', 'violin', 'piano',\n",
       "       'piano', 'santour', 'ney', 'santour', 'tar', 'tar', 'ney', 'tar',\n",
       "       'santour', 'ney', 'violin', 'piano', 'tar', 'violin', 'tar',\n",
       "       'setar', 'tar', 'violin', 'setar', 'piano', 'setar', 'violin',\n",
       "       'ney', 'violin', 'violin', 'violin', 'ney', 'ney', 'setar', 'ney',\n",
       "       'tar', 'tar', 'tar', 'tar', 'setar', 'tar', 'santour', 'ney',\n",
       "       'tar', 'santour', 'piano', 'ney', 'ney', 'violin', 'piano',\n",
       "       'setar', 'violin', 'piano', 'tar', 'ney', 'setar', 'tar', 'ney',\n",
       "       'tar', 'tar', 'piano', 'piano', 'violin', 'santour', 'piano',\n",
       "       'santour', 'piano', 'setar', 'ney', 'violin', 'piano', 'santour',\n",
       "       'santour', 'santour', 'piano', 'santour', 'violin', 'violin',\n",
       "       'tar', 'santour', 'santour', 'piano', 'violin', 'tar', 'violin',\n",
       "       'setar', 'setar', 'violin', 'piano', 'violin', 'ney', 'piano',\n",
       "       'ney', 'setar', 'santour', 'setar', 'ney', 'santour', 'ney',\n",
       "       'piano', 'setar', 'tar', 'violin', 'santour', 'piano', 'violin',\n",
       "       'violin', 'santour', 'piano', 'piano', 'tar', 'violin', 'tar',\n",
       "       'violin', 'ney', 'ney', 'tar', 'tar', 'violin', 'ney', 'ney',\n",
       "       'piano', 'tar', 'santour', 'santour', 'piano', 'piano', 'ney',\n",
       "       'ney', 'ney', 'violin', 'ney', 'ney', 'ney', 'ney', 'tar', 'piano'],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9060402684563759"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real lable is ['santour'] and prediction is ['santour']\n"
     ]
    }
   ],
   "source": [
    "sample = X_test[0]\n",
    "pred = clf.predict([sample])\n",
    "pred_label = encoder.inverse_transform([pred])\n",
    "real_label = encoder.inverse_transform([y_test[0]])\n",
    "print(f\"real lable is {real_label} and prediction is {pred_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d66bb7d4f8a116e2925a95bebe6e04f8fc3c8ed65e8572fe262df87356dbbb5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('data': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
